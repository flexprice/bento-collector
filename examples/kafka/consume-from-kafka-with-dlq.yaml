# Bento Flexprice - Staging Kafka Consumer
# Consumes from bento-testing topic and sends to Flexprice

input:
  kafka:
    # Staging Kafka brokers
    addresses: 
      - ${FLEXPRICE_KAFKA_BROKERS}
    
    # Test topic (configurable via environment)
    topics:
      - ${FLEXPRICE_KAFKA_TOPIC:bento-testing}
    
    # Consumer group (use a new group name to skip old messages)
    consumer_group: ${FLEXPRICE_KAFKA_CONSUMER_GROUP:bento-flexprice-v3}
    
    # Start from NEWEST to skip old broken messages
    start_from_oldest: false
    
    # SASL Authentication for Confluent Cloud
    tls:
      enabled: true
    
    sasl:
      mechanism: PLAIN
      user: ${FLEXPRICE_KAFKA_SASL_USER}
      password: ${FLEXPRICE_KAFKA_SASL_PASSWORD}
    
    # Client ID
    client_id: ${FLEXPRICE_KAFKA_CLIENT_ID:bento-flexprice-collector}
    
    # Performance tuning for batching
    commit_period: 1s
    max_processing_period: 100ms
    
    # Fetch settings - get messages faster for batching
    fetch_buffer_cap: 256  # Fetch up to 256 messages at once
    
    # Only commit offsets when output succeeds (default behavior, but explicit for clarity)
    checkpoint_limit: 1

pipeline:
  processors:
    # Store original event in metadata for DLQ (before transformation)
    - mapping: |
        # Preserve original event for potential DLQ
        meta.original_event = this.string()
        meta.original_topic = meta("kafka_topic")
        meta.original_partition = meta("kafka_partition")
        meta.original_offset = meta("kafka_offset")
        
        # Pass through the message unchanged
        root = this
    
    # Transform Kafka message to Flexprice event format
    - mapping: |
        # Required fields
        root.event_name = this.event_name
        root.external_customer_id = this.external_customer_id.or(this.customer_id)
        
        # Properties - ensure all values are strings
        root.properties = if this.properties.type() == "object" {
          this.properties.map_each(p -> p.value.string())
        } else {
          {}
        }
        
        # Source tracking
        root.source = "kafka-staging-bento"
        
        # Timestamp handling
        root.timestamp = this.timestamp.or(now().format_timestamp("2006-01-02T15:04:05Z07:00"))
        
        # Optional fields
        root.event_id = this.event_id.or("")
        root.customer_id = this.customer_id.or("")
    
    # Log each event
    - log:
        level: INFO
        message: |
          [KAFKA→FLEXPRICE] Processing event:
          - Event Name: ${!json("event_name")}
          - Customer ID: ${!json("external_customer_id")}
          - Timestamp: ${!json("timestamp")}
    

output:
  # Fallback pattern: Try Flexprice with retries, then send to DQL if all retries fail
  fallback:
    # Primary output: Flexprice API with retry logic
    - retry:
        max_retries: 3
        backoff:
          initial_interval: 1s
          max_interval: 30s
        output:
          flexprice:
            api_host: ${FLEXPRICE_API_HOST}
            api_key: ${FLEXPRICE_API_KEY}
            scheme: https
            
            # Batching configuration - efficiently send multiple events in bulk
            batching:
              count: 10      # Send bulk when we have 10 events
              period: 2s     # Or send after 2 seconds (increased for Kafka lag)
            
            # Maximum concurrent requests
            max_in_flight: 10
    
    # Dead Letter Queue (DLQ): Send failed events to another Kafka topic
    # Events sent here have failed after 3 retry attempts to Flexprice API
    - resource: dlq_output

logger:
  level: INFO
  format: logfmt
  add_timestamp: true

# Output resources - defined separately so we can add processors
output_resources:
  - label: dlq_output
    processors:
      - log:
          level: WARN
          message: |
            ⚠️ [DLQ] Sending failed event to Dead Letter Queue:
            - Event Name: ${!json("event_name")}
            - Customer ID: ${!json("external_customer_id")}
            - Topic: ${FLEXPRICE_KAFKA_DLQ_TOPIC:bento-testing-dlq}
    kafka:
      # Same Kafka brokers as input
      addresses:
        - ${FLEXPRICE_KAFKA_BROKERS}
      
      # DLQ topic for failed events (configurable via environment)
      topic: ${FLEXPRICE_KAFKA_DLQ_TOPIC:bento-testing-dlq}
      
      # SASL Authentication (same as input)
      tls:
        enabled: true
      
      sasl:
        mechanism: PLAIN
        user: ${FLEXPRICE_KAFKA_SASL_USER}
        password: ${FLEXPRICE_KAFKA_SASL_PASSWORD}
      
      # Client ID for DLQ producer
      client_id: ${FLEXPRICE_KAFKA_CLIENT_ID:bento-flexprice-dlq}
      
      # Batching for DLQ
      batching:
        count: 10
        period: 1s
